Changed directory to /home/grads/r/rishit/code/Pyfr_venv/PyFR/examples/inc_cylinder_2d.

JobID: 55189
======
Time: Fri Oct  1 16:19:30 CDT 2021
Running on master node: spitfire-ng20.spitfire.engr.tamu.edu
Current directory: /home/grads/r/rishit/code/Pyfr_venv/PyFR/examples/inc_cylinder_2d

numtasks=1, numnodes=1, mpi_tasks_per_node=1 (OMP_NUM_THREADS=)

Executing command:
==================
mpiexec -n 1 /home/grads/r/rishit/code/Pyfr_venv/bin/python /home/grads/r/rishit/code/Pyfr_venv/PyFR/pyfr/pyfr run -b cuda inc_cylinder_2d.pyfrm inc_cylinder_2d.ini

[spitfire-ng20.spitfire.engr.tamu.edu:03624] OPAL ERROR: Unreachable in file pmix3x_client.c at line 112
*** An error occurred in MPI_Init
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
***    and potentially your MPI job)
[spitfire-ng20.spitfire.engr.tamu.edu:03624] Local abort before MPI_INIT completed completed successfully, but am not able to aggregate error messages, and not able to guarantee that all other processes were killed!
-------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code.. Per user-direction, the job has been aborted.
-------------------------------------------------------
--------------------------------------------------------------------------
mpiexec detected that one or more processes exited with non-zero status, thus causing
the job to be terminated. The first process to do so was:

  Process name: [[24470,1],0]
  Exit code:    1
--------------------------------------------------------------------------
